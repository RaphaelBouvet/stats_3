{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation, Model Selection & Regularisation\n",
    "\n",
    "In this notebook we will introduce the concepts below, and how they can be implemented in `scikit-learn`.\n",
    "* Cross validation - a method for estimating the test error rate when test data is not available\n",
    "* Model selection - how we use cross validation to select which model (from a selection) we should use for a particular data set\n",
    "* Regularisation - an adaptation of linear regression to make it more flexible\n",
    "\n",
    "[This video](https://www.youtube.com/watch?v=DQWI1kvmwRg) describes some of the ideas you will face in the coming notebook. The ideas we are covering here are described much more throughly in **ISLR** (see suggested sections in module overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "We have already seen the notion of splitting *test* and *training sets* in order to asses model performance. Now we will introduce the idea of *validation sets*.\n",
    "\n",
    "Once again **ISTL** (Section 5.1) provides a very clear overview of how these technqiues work:\n",
    "\n",
    ">Resampling methods are an indispensable tool in modern statistics. They\n",
    "involve repeatedly drawing samples from a training set and refitting a model\n",
    "of interest on each sample in order to obtain additional information about\n",
    "the fitted model. For example, in order to estimate the variability of a linear\n",
    "regression fit, we can repeatedly draw different samples from the training\n",
    "data, fit a linear regression to each new sample, and then examine the\n",
    "extent to which the resulting fits differ. Such an approach may allow us to\n",
    "obtain information that would not be available from fitting the model only\n",
    "once using the original training sample.\n",
    "\n",
    ">Resampling approaches can be computationally expensive, because they\n",
    "involve fitting the same statistical method multiple times using different\n",
    "subsets of the training data. However, due to recent advances in computing\n",
    "power, the computational requirements of resampling methods generally\n",
    "are not prohibitive. [...] cross-validation can be used to estimate the test\n",
    "error associated with a given statistical learning method in order to evaluate\n",
    "its performance, or to select the appropriate level of flexibility. The process\n",
    "of evaluating a model’s performance is known as model assessment, whereas model\n",
    "the process of selecting the proper level of flexibility for a model is known as assessment\n",
    "model selection.\n",
    "\n",
    "The [diagram](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7) below illustrates this process. Here the train and validation sets are used to do model assesment and model selection (NOTE: the test set is strictly forbidden from being used in any way during this process!). Once a model is selected the test set is used to do a final assesment of performance to see if the model selected will generalise as well as predicted.\n",
    "\n",
    "<img src=\"././images/testtrainvalid.png\" width=\"450px\">\n",
    "\n",
    "There is a simple overview these ideas [here](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7), and a more thorough overview [here](https://machinelearningmastery.com/difference-test-validation-datasets/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation\n",
    "\n",
    "A very common method called *k-fold* is often used, which actually splits the training set multiple times. This allows us to assess the accuracy of the model over $k$ validation splits of data. The [image below](http://ethen8181.github.io/machine-learning/model_selection/model_selection.html) illustrates how this works for $k = 5$ splits.\n",
    "\n",
    "<img src=\"././images/kfold.png\" width=\"450px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scikit-learn` documentation offers a simple [example](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) of implementing k-fold on some dummy data. We will examine this below. NOTE: The `scikit-learn` documentation is **FANSTASTIC(!)** and contains working examples of every function, it should always be the first place you look when you wish to implement a new function.\n",
    "\n",
    "**Task 1:** \n",
    "\n",
    "* Have a look at the code below and check you understand what is going on. (Add some print statements in various places to help.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=2, random_state=None, shuffle=False)\n",
      "TRAIN: [2 3] VALID: [0 1]\n",
      "TRAIN: [0 1] VALID: [2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([['A', 'B'], ['C', 'D'], ['E', 'F'], ['G', 'H']])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=2) # here we choose the number of folds (or splits) we will make\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "for train_index, valid_index in kf.split(X): # kf.split(X) is an iterable which gives us the indices of the data in each fold\n",
    "    print(\"TRAIN:\", train_index, \"VALID:\", valid_index)\n",
    "    X_train, X_valid = X[train_index], X[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply this to any data set to perform operations as it gives us the dataframe/numpy array indicies in each loop to select the appropriate data for each fold. For example we can apply this to the auto data set. This contains rows which correspond to individual cars and their attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0         130    3504          12.0    70   \n",
       "1  15.0          8         350.0         165    3693          11.5    70   \n",
       "2  18.0          8         318.0         150    3436          11.0    70   \n",
       "3  16.0          8         304.0         150    3433          12.0    70   \n",
       "4  17.0          8         302.0         140    3449          10.5    70   \n",
       "\n",
       "   origin                       name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('./data/Auto.csv')\n",
    "auto = auto[auto.horsepower != '?']\n",
    "auto['horsepower'] = auto.horsepower.astype(int)\n",
    "auto.reset_index(inplace=True, drop=True)\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = auto.pop('mpg') # mpg will be our target and so we remove this into a seperate array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we are trying to predict 'mpg' from our other automobile data features. We can use KFold to iterate over the number of splits we choose.\n",
    "\n",
    "**Task 2:**\n",
    "* try adding print statements for the size of the dataframes in each split\n",
    "* try increasing the number of splits and re-run your code\n",
    "* use the code below to print a car name contained in the train and validation data set, for each split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=8, random_state=None, shuffle=False)\n",
      "------------------------------\n",
      "This is split no: 1\n",
      "peugeot 304\n",
      "buick skylark 320\n",
      "------------------------------\n",
      "This is split no: 2\n",
      "buick skylark 320\n",
      "peugeot 304\n",
      "------------------------------\n",
      "This is split no: 3\n",
      "buick skylark 320\n",
      "ford maverick\n",
      "------------------------------\n",
      "This is split no: 4\n",
      "buick skylark 320\n",
      "subaru\n",
      "------------------------------\n",
      "This is split no: 5\n",
      "buick skylark 320\n",
      "dodge aspen se\n",
      "------------------------------\n",
      "This is split no: 6\n",
      "buick skylark 320\n",
      "honda civic cvcc\n",
      "------------------------------\n",
      "This is split no: 7\n",
      "buick skylark 320\n",
      "mercedes benz 300d\n",
      "------------------------------\n",
      "This is split no: 8\n",
      "buick skylark 320\n",
      "toyota tercel\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=8) # here we choose the number of folds (or splits) we will make\n",
    "kf.get_n_splits(auto)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "\n",
    "split_counter = 1\n",
    "for train_index, valid_index in kf.split(auto): # kf.split(X) is an iterable which gives us the indices of the data in each fold\n",
    "    print('-'*30)\n",
    "    print('This is split no: {}'.format(split_counter))\n",
    "    split_counter += 1 \n",
    "    X_train, X_valid = auto.iloc[train_index], auto.iloc[valid_index] # must use .iloc because its a dataframe this time\n",
    "    y_train, y_valid = mpg[train_index], mpg[valid_index]\n",
    "    \n",
    "    # your code here\n",
    "    print(X_train.name.unique()[1])\n",
    "    print(X_valid.name.unique()[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto.drop('name', axis=1, errors='ignore') # we do not need the car names so remove for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same loop to fit and evaluate our linear regression model on each train/validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "This is split no: 1\n",
      "training MSE: 11.284070590566001\n",
      "validation MSE: 14.974307651304168\n",
      "------------------------------\n",
      "This is split no: 2\n",
      "training MSE: 11.155158050598772\n",
      "validation MSE: 10.905952427081171\n",
      "------------------------------\n",
      "This is split no: 3\n",
      "training MSE: 12.16010513687152\n",
      "validation MSE: 5.991708610108162\n",
      "------------------------------\n",
      "This is split no: 4\n",
      "training MSE: 9.921674145405685\n",
      "validation MSE: 15.587544657621601\n",
      "------------------------------\n",
      "This is split no: 5\n",
      "training MSE: 7.977511689294959\n",
      "validation MSE: 27.844743081984223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "split_counter = 1\n",
    "mse_scores = [] # create empty list of scores for each split\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(auto)\n",
    "\n",
    "for train_index, valid_index in kf.split(auto): # kf.split(X) is an iterable which gives us the indices of the data in each fold\n",
    "    print('-'*30)\n",
    "    print('This is split no: {}'.format(split_counter))\n",
    "    split_counter += 1 \n",
    "    X_train, X_valid = auto.iloc[train_index], auto.iloc[valid_index] # must use .iloc because its a dataframe this time\n",
    "    y_train, y_valid = mpg[train_index], mpg[valid_index]\n",
    "    \n",
    "    \n",
    "    #### fit polynomial to train data in this split\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    \n",
    "    #### eval & print MSE training results in this split\n",
    "    mpg_train_pred = lin_reg.predict(X_train)\n",
    "    mse_train = mean_squared_error(y_train, mpg_train_pred)\n",
    "    print('training MSE: {0}'.format(mse_train))\n",
    "    \n",
    "    #### do the same for validation split\n",
    "    mpg_valid_pred = lin_reg.predict(X_valid)\n",
    "    mse_valid = mean_squared_error(y_valid, mpg_valid_pred)\n",
    "    print('validation MSE: {0}'.format(mse_valid))\n",
    "    \n",
    "    mse_scores.append(mse_valid) # assign validation MSE score to list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using k-fold cross validation we can analyse the validation MSE result for each split to assess the overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION SET MSE SCORES\n",
      "mean MSE: 15.060851285619865\n",
      "std MSE: 7.255691814890938\n"
     ]
    }
   ],
   "source": [
    "mse_scores  = np.array(mse_scores)\n",
    "print('VALIDATION SET MSE SCORES')\n",
    "print('mean MSE:', mse_scores.mean())\n",
    "print('std MSE:', mse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation in practice in sklearn\n",
    "Most of the time we do not care about having access to each split. `Scikit-Learn` provide a much easier way to do all of this with the function `cross_val_score`. This allows us to do the same as above but in much less code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MSE: 15.060851285619865\n",
      "std MSE: 7.255691814890938\n",
      "[-14.97430765 -10.90595243  -5.99170861 -15.58754466 -27.84474308]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "cv_scores = cross_val_score(lin_reg, auto, mpg, cv = 5, scoring='neg_mean_squared_error') # utilisation de neg car convention dans sklearn que higher scoring val is better\n",
    "\n",
    "print('mean MSE:',np.mean(-cv_scores))\n",
    "print('std MSE:',np.std(-cv_scores))\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:**\n",
    "\n",
    "* Make sure you understand the output of the cross_val_score above (i.e. What is cv_scores?)\n",
    "* Investigate what the `cross_val_predict` function does.\n",
    "* Import and implement this on the same data as above.\n",
    "* What are the outputs of this function?\n",
    "* Can you use these to evaluate the results of your cross validation?\n",
    "* Do the cross-validation scores give you confidence this model is providing a useful prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross_val_predict\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "cv_predict = cross_val_predict(lin_reg, auto, mpg, cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_predict returns the predicted value when the element was in the validation set.  \n",
    "It is not suitable for evaluation because it blends the 5 models together...  \n",
    "It is best used for data viz (or Model blending ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7689592371135645\n",
      "0.9250932680525775\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.sqrt(-cv_scores)))\n",
    "print(np.std(np.sqrt(-cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.805007486571799"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 1: wine cross-validation\n",
    "\n",
    "You must predict the alcohol content of various wines based on their other attributes.\n",
    "\n",
    "* Split the data into train and test data sets (Ensure you use the option: `random_state = 28`).\n",
    "* Perform linear regression using k-fold cross validation(ensure you use 5 folds). Return the cross validation MSE errors. Return the mean and standard deviations of these.\n",
    "* Evaluate the performance of the model on the test set.\n",
    "* Compare the cross-validation error and the test error (MSE). What do you find? \n",
    "* Try removing the random_state option. What happens to your results? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### your solution here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "wine = pd.read_csv('./data/wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol = wine.pop('Alcohol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grape</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-2.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>1.14</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>1.74</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.42</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>2.22</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.42</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.35</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>1.83</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Grape  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0        1       -0.56  0.23              -1.17       1.91           0.81   \n",
       "1        1       -0.50 -0.83              -2.48       0.02           0.57   \n",
       "2        1        0.02  1.11              -0.27       0.09           0.81   \n",
       "3        1       -0.35  0.49              -0.81       0.93           2.48   \n",
       "4        1        0.23  1.84               0.45       1.28           0.81   \n",
       "..     ...         ...   ...                ...        ...            ...   \n",
       "173      3        2.97  0.30               0.30      -0.33          -0.98   \n",
       "174      3        1.41  0.41               1.05       0.16          -0.79   \n",
       "175      3        1.74 -0.39               0.15       1.42          -1.13   \n",
       "176      3        0.23  0.01               0.15       1.42          -1.03   \n",
       "177      3        1.58  1.36               1.50      -0.26          -0.39   \n",
       "\n",
       "     Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "0          1.03                 -0.66             1.22             0.25  0.36   \n",
       "1          0.73                 -0.82            -0.54            -0.29  0.40   \n",
       "2          1.21                 -0.50             2.13             0.27  0.32   \n",
       "3          1.46                 -0.98             1.03             1.18 -0.43   \n",
       "4          0.66                  0.23             0.40            -0.32  0.36   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173       -1.42                  1.27            -0.93             1.14 -1.39   \n",
       "174       -1.28                  0.55            -0.32             0.97 -1.13   \n",
       "175       -1.34                  0.55            -0.42             2.22 -1.61   \n",
       "176       -1.35                  1.35            -0.23             1.83 -1.56   \n",
       "177       -1.27                  1.59            -0.42             1.79 -1.52   \n",
       "\n",
       "     OD280/OD315 of diluted wines  Proline  \n",
       "0                            1.84     1.01  \n",
       "1                            1.11     0.96  \n",
       "2                            0.79     1.39  \n",
       "3                            1.18     2.33  \n",
       "4                            0.45    -0.04  \n",
       "..                            ...      ...  \n",
       "173                         -1.23    -0.02  \n",
       "174                         -1.48     0.01  \n",
       "175                         -1.48     0.28  \n",
       "176                         -1.40     0.30  \n",
       "177                         -1.42    -0.59  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine, alcohol,random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MSE: 0.4771472419568701\n",
      "mean RMSE : 0.6828399536518984\n",
      "std MSE: 0.13726764524713442\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "cv_scores = cross_val_score(lin_reg,X_train,y_train,cv=5,scoring='neg_mean_squared_error')\n",
    "print('mean MSE:',np.mean(-cv_scores))\n",
    "print(f'mean RMSE : {np.mean(np.sqrt(-cv_scores))}')\n",
    "print('std MSE:',np.std(-cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0.47723 | RMSE 0.69082\n"
     ]
    }
   ],
   "source": [
    "lin_reg.fit(X_train,y_train)\n",
    "y_test_predict = lin_reg.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test,y_test_predict)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "print(f'MSE {mse_test:.5f} | RMSE {rmse_test:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean   -0.000112\n",
       "std     0.999626\n",
       "Name: Alcohol, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol.agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Regularisation\n",
    "\n",
    "An alternative to choosing models which contains smaller numbers of features is to use a method that *constrains* or *regularises* the coefficent estimates assigned to each feature, or that shrinks the coefficient towards zero. This technique is very similar to *least squares* which we have been using until now. Please refer to Section in 6.2 **ISTL** for a fuller explanation of this.\n",
    "\n",
    "When we move to use a regularised linear regression for prediction the additional term means that we now have a model parameter that requires setting. These terms are referred to as *hyperparameters* in machine learning. In practice this introduces another additional unknown parameter which we must choose somewhere in our modelling. It is common practice to run several models, each with different values of this hyperparameter, and then assess the error of each using cross validation for comparison.\n",
    "\n",
    "For now we will focus on how to implement Lasso and Ridge regression in sklearn. These are both types of regularised linear regression.\n",
    "\n",
    "#### Lasso regression in sklearn\n",
    "\n",
    "In this example we aim to predict credit rating of individual customers. To train and predict using a Lasso regression we follow much the same procedure as we have seen before in `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ressources supplémentaires si vous souhaitez creuser :\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net\n",
    "\n",
    "http://eric.univ-lyon2.fr/~ricco/cours/slides/regularized_regression.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Student</th>\n",
       "      <th>Married</th>\n",
       "      <th>Balance</th>\n",
       "      <th>African American</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Caucasian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.891</td>\n",
       "      <td>3606</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.882</td>\n",
       "      <td>4897</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Limit  Cards  Age  Education  Gender  Student  Married  Balance  \\\n",
       "0   14.891   3606      2   34         11       0        0        1      333   \n",
       "1  106.025   6645      3   82         15       1        1        1      903   \n",
       "2  104.593   7075      4   71         11       0        0        0      580   \n",
       "3  148.924   9504      3   36         11       1        0        0      964   \n",
       "4   55.882   4897      2   68         16       0        0        1      331   \n",
       "\n",
       "   African American  Asian  Caucasian  \n",
       "0                 0      0          1  \n",
       "1                 0      1          0  \n",
       "2                 0      1          0  \n",
       "3                 0      1          0  \n",
       "4                 0      0          1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit = pd.read_csv('./data/credit_modified.csv')\n",
    "rating = credit.pop('Rating')\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### splitting train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(credit, rating, random_state = 91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean MSE: 148.3658024815139\n",
      "std MSE: 22.577610846122578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = 10)\n",
    "cv_scores = cross_val_score(lasso, X_train, y_train, cv = 5, scoring='neg_mean_squared_error')\n",
    "print('mean MSE:',np.mean(-cv_scores))\n",
    "print('std MSE:',np.std(-cv_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can alter the alpha parameter to change the amount of regularisation the model uses (try this yourself! - vary the value by at least factors of 10). With increases in regularisation we expect a reduction in the *variance* of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Lasso with grid search\n",
    "\n",
    "In practice we do not want to vary hyperparameters by hand to find which value is best (the model with minimum cross validation error). Of course `scikit-learn` has a function that automates this for you. Using `GridSearchCV` we pass a dictionary of parameter values we wish to investigate. The function will fit each model we have listed and calculate the cross validation error of each. It provides all the results through the object it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>-134.693531</td>\n",
       "      <td>-105.857049</td>\n",
       "      <td>-101.376944</td>\n",
       "      <td>-87.569097</td>\n",
       "      <td>-78.913304</td>\n",
       "      <td>-76.137420</td>\n",
       "      <td>-109.786540</td>\n",
       "      <td>-103.885686</td>\n",
       "      <td>-106.104721</td>\n",
       "      <td>-113.455931</td>\n",
       "      <td>-101.778022</td>\n",
       "      <td>16.450021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>-134.553201</td>\n",
       "      <td>-105.948212</td>\n",
       "      <td>-101.096381</td>\n",
       "      <td>-87.881139</td>\n",
       "      <td>-78.937345</td>\n",
       "      <td>-76.585584</td>\n",
       "      <td>-109.682491</td>\n",
       "      <td>-103.106018</td>\n",
       "      <td>-106.112572</td>\n",
       "      <td>-113.688788</td>\n",
       "      <td>-101.759173</td>\n",
       "      <td>16.329243</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>-133.132694</td>\n",
       "      <td>-106.809300</td>\n",
       "      <td>-98.722275</td>\n",
       "      <td>-91.394863</td>\n",
       "      <td>-79.351692</td>\n",
       "      <td>-78.012317</td>\n",
       "      <td>-108.680986</td>\n",
       "      <td>-96.604537</td>\n",
       "      <td>-106.093953</td>\n",
       "      <td>-115.062267</td>\n",
       "      <td>-101.386489</td>\n",
       "      <td>15.688554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>-127.851853</td>\n",
       "      <td>-111.017555</td>\n",
       "      <td>-92.827631</td>\n",
       "      <td>-106.006184</td>\n",
       "      <td>-89.048154</td>\n",
       "      <td>-82.339570</td>\n",
       "      <td>-105.158164</td>\n",
       "      <td>-94.934777</td>\n",
       "      <td>-102.310102</td>\n",
       "      <td>-122.139519</td>\n",
       "      <td>-103.363351</td>\n",
       "      <td>13.605513</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 3}</td>\n",
       "      <td>-132.499698</td>\n",
       "      <td>-117.173048</td>\n",
       "      <td>-106.238114</td>\n",
       "      <td>-112.301661</td>\n",
       "      <td>-94.847286</td>\n",
       "      <td>-76.537019</td>\n",
       "      <td>-102.509314</td>\n",
       "      <td>-98.851062</td>\n",
       "      <td>-105.902336</td>\n",
       "      <td>-131.338637</td>\n",
       "      <td>-107.819817</td>\n",
       "      <td>15.910751</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.003313      0.000420         0.001259        0.000101       0.001   \n",
       "1       0.002407      0.000285         0.001003        0.000078        0.01   \n",
       "2       0.001800      0.000137         0.000935        0.000083         0.1   \n",
       "3       0.001513      0.000019         0.000883        0.000007           1   \n",
       "4       0.001557      0.000121         0.001003        0.000195           3   \n",
       "\n",
       "             params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.001}        -134.693531        -105.857049        -101.376944   \n",
       "1   {'alpha': 0.01}        -134.553201        -105.948212        -101.096381   \n",
       "2    {'alpha': 0.1}        -133.132694        -106.809300         -98.722275   \n",
       "3      {'alpha': 1}        -127.851853        -111.017555         -92.827631   \n",
       "4      {'alpha': 3}        -132.499698        -117.173048        -106.238114   \n",
       "\n",
       "   split3_test_score  split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0         -87.569097         -78.913304         -76.137420        -109.786540   \n",
       "1         -87.881139         -78.937345         -76.585584        -109.682491   \n",
       "2         -91.394863         -79.351692         -78.012317        -108.680986   \n",
       "3        -106.006184         -89.048154         -82.339570        -105.158164   \n",
       "4        -112.301661         -94.847286         -76.537019        -102.509314   \n",
       "\n",
       "   split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0        -103.885686        -106.104721        -113.455931      -101.778022   \n",
       "1        -103.106018        -106.112572        -113.688788      -101.759173   \n",
       "2         -96.604537        -106.093953        -115.062267      -101.386489   \n",
       "3         -94.934777        -102.310102        -122.139519      -103.363351   \n",
       "4         -98.851062        -105.902336        -131.338637      -107.819817   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0       16.450021                3  \n",
       "1       16.329243                2  \n",
       "2       15.688554                1  \n",
       "3       13.605513                4  \n",
       "4       15.910751                5  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "lasso = Lasso(max_iter=10000)\n",
    "\n",
    "param_grid = [\n",
    " {'alpha': [0.001, 0.01, 0.1, 1, 3, 10, 100, 1000]},\n",
    " ]\n",
    "\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "grid_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` also returns a model (with the best hyperparmeter combination it found) which has been fitted one final time to all of the training data. Therefore it is ready to make predictions on the testing set. The model can be accessed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>-134.693531</td>\n",
       "      <td>-105.857049</td>\n",
       "      <td>-101.376944</td>\n",
       "      <td>-87.569097</td>\n",
       "      <td>-78.913304</td>\n",
       "      <td>-76.137420</td>\n",
       "      <td>-109.786540</td>\n",
       "      <td>-103.885686</td>\n",
       "      <td>-106.104721</td>\n",
       "      <td>-113.455931</td>\n",
       "      <td>-101.778022</td>\n",
       "      <td>16.450021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>-134.553201</td>\n",
       "      <td>-105.948212</td>\n",
       "      <td>-101.096381</td>\n",
       "      <td>-87.881139</td>\n",
       "      <td>-78.937345</td>\n",
       "      <td>-76.585584</td>\n",
       "      <td>-109.682491</td>\n",
       "      <td>-103.106018</td>\n",
       "      <td>-106.112572</td>\n",
       "      <td>-113.688788</td>\n",
       "      <td>-101.759173</td>\n",
       "      <td>16.329243</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>-133.132694</td>\n",
       "      <td>-106.809300</td>\n",
       "      <td>-98.722275</td>\n",
       "      <td>-91.394863</td>\n",
       "      <td>-79.351692</td>\n",
       "      <td>-78.012317</td>\n",
       "      <td>-108.680986</td>\n",
       "      <td>-96.604537</td>\n",
       "      <td>-106.093953</td>\n",
       "      <td>-115.062267</td>\n",
       "      <td>-101.386489</td>\n",
       "      <td>15.688554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>-127.851853</td>\n",
       "      <td>-111.017555</td>\n",
       "      <td>-92.827631</td>\n",
       "      <td>-106.006184</td>\n",
       "      <td>-89.048154</td>\n",
       "      <td>-82.339570</td>\n",
       "      <td>-105.158164</td>\n",
       "      <td>-94.934777</td>\n",
       "      <td>-102.310102</td>\n",
       "      <td>-122.139519</td>\n",
       "      <td>-103.363351</td>\n",
       "      <td>13.605513</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 3}</td>\n",
       "      <td>-132.499698</td>\n",
       "      <td>-117.173048</td>\n",
       "      <td>-106.238114</td>\n",
       "      <td>-112.301661</td>\n",
       "      <td>-94.847286</td>\n",
       "      <td>-76.537019</td>\n",
       "      <td>-102.509314</td>\n",
       "      <td>-98.851062</td>\n",
       "      <td>-105.902336</td>\n",
       "      <td>-131.338637</td>\n",
       "      <td>-107.819817</td>\n",
       "      <td>15.910751</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>-182.681016</td>\n",
       "      <td>-155.361568</td>\n",
       "      <td>-179.884644</td>\n",
       "      <td>-148.842090</td>\n",
       "      <td>-141.841896</td>\n",
       "      <td>-86.351859</td>\n",
       "      <td>-129.718484</td>\n",
       "      <td>-131.176340</td>\n",
       "      <td>-143.631521</td>\n",
       "      <td>-181.271903</td>\n",
       "      <td>-148.076132</td>\n",
       "      <td>28.028584</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>-188.380866</td>\n",
       "      <td>-143.744333</td>\n",
       "      <td>-184.078341</td>\n",
       "      <td>-145.491583</td>\n",
       "      <td>-157.301014</td>\n",
       "      <td>-103.112064</td>\n",
       "      <td>-146.957766</td>\n",
       "      <td>-126.231725</td>\n",
       "      <td>-143.006029</td>\n",
       "      <td>-181.543599</td>\n",
       "      <td>-151.984732</td>\n",
       "      <td>25.542857</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'alpha': 1000}</td>\n",
       "      <td>-188.587767</td>\n",
       "      <td>-146.517162</td>\n",
       "      <td>-180.483375</td>\n",
       "      <td>-143.257202</td>\n",
       "      <td>-158.504388</td>\n",
       "      <td>-103.017203</td>\n",
       "      <td>-150.127246</td>\n",
       "      <td>-121.916885</td>\n",
       "      <td>-144.912869</td>\n",
       "      <td>-185.805136</td>\n",
       "      <td>-152.312923</td>\n",
       "      <td>26.074170</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.003313      0.000420         0.001259        0.000101       0.001   \n",
       "1       0.002407      0.000285         0.001003        0.000078        0.01   \n",
       "2       0.001800      0.000137         0.000935        0.000083         0.1   \n",
       "3       0.001513      0.000019         0.000883        0.000007           1   \n",
       "4       0.001557      0.000121         0.001003        0.000195           3   \n",
       "5       0.001675      0.000654         0.001006        0.000267          10   \n",
       "6       0.001357      0.000019         0.000879        0.000012         100   \n",
       "7       0.001328      0.000028         0.000887        0.000019        1000   \n",
       "\n",
       "             params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.001}        -134.693531        -105.857049        -101.376944   \n",
       "1   {'alpha': 0.01}        -134.553201        -105.948212        -101.096381   \n",
       "2    {'alpha': 0.1}        -133.132694        -106.809300         -98.722275   \n",
       "3      {'alpha': 1}        -127.851853        -111.017555         -92.827631   \n",
       "4      {'alpha': 3}        -132.499698        -117.173048        -106.238114   \n",
       "5     {'alpha': 10}        -182.681016        -155.361568        -179.884644   \n",
       "6    {'alpha': 100}        -188.380866        -143.744333        -184.078341   \n",
       "7   {'alpha': 1000}        -188.587767        -146.517162        -180.483375   \n",
       "\n",
       "   split3_test_score  split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0         -87.569097         -78.913304         -76.137420        -109.786540   \n",
       "1         -87.881139         -78.937345         -76.585584        -109.682491   \n",
       "2         -91.394863         -79.351692         -78.012317        -108.680986   \n",
       "3        -106.006184         -89.048154         -82.339570        -105.158164   \n",
       "4        -112.301661         -94.847286         -76.537019        -102.509314   \n",
       "5        -148.842090        -141.841896         -86.351859        -129.718484   \n",
       "6        -145.491583        -157.301014        -103.112064        -146.957766   \n",
       "7        -143.257202        -158.504388        -103.017203        -150.127246   \n",
       "\n",
       "   split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0        -103.885686        -106.104721        -113.455931      -101.778022   \n",
       "1        -103.106018        -106.112572        -113.688788      -101.759173   \n",
       "2         -96.604537        -106.093953        -115.062267      -101.386489   \n",
       "3         -94.934777        -102.310102        -122.139519      -103.363351   \n",
       "4         -98.851062        -105.902336        -131.338637      -107.819817   \n",
       "5        -131.176340        -143.631521        -181.271903      -148.076132   \n",
       "6        -126.231725        -143.006029        -181.543599      -151.984732   \n",
       "7        -121.916885        -144.912869        -185.805136      -152.312923   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0       16.450021                3  \n",
       "1       16.329243                2  \n",
       "2       15.688554                1  \n",
       "3       13.605513                4  \n",
       "4       15.910751                5  \n",
       "5       28.028584                6  \n",
       "6       25.542857                7  \n",
       "7       26.074170                8  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:**\n",
    "* How many times will the lasso model be fitted when the GridSearchCV function is called above?\n",
    "\n",
    "<details><summary>Hint</summary><br>\n",
    "Check what the `refit=True` parameter does in GridSearchCV\n",
    "</details>\n",
    "\n",
    "* Look through the columns of the `grid_results` dataframe. Try and understand what the table contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nb of fitted with GridSearchCV = 80 (8*alpha *10fold)\n",
    "in grid resuls =>\n",
    " - Fit times mean/std\n",
    " - mean score time (validations)\n",
    " - Test score for each fold (values, mean,sd and rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "\n",
    "Congratulations! You have just done your first model hyperparameter tuning in `scikit-learn`! \n",
    "\n",
    "If we have a dataset for which we are interested in developing a predictive model. We do not know beforehand which model will perform best for this particular data or problem. Therefore, we fit and evaluate a number of different models to our data. The models could also be of varying type as well as flexibility (e.g. random forests, support vector machines, linear regression). We then need to decide which of our models we will choose to use in our final product.\n",
    "\n",
    "As **ISLR** states:\n",
    "> \"we can directly estimate the test error using the validation set and cross-validation methods\n",
    "discussed in Chapter 5. We can compute the validation set error or the\n",
    "cross-validation error for each model under consideration, and then select\n",
    "the model for which the resulting estimated test error is smallest.\"\n",
    "\n",
    "This works as a simple rule, which we will follow for the remainder of this notebook. However in practice the selection can sometimes be a bit more nuanced. Read more detail [here](https://machinelearningmastery.com/a-gentle-introduction-to-model-selection-for-machine-learning/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Task 5: Ridge regression in sklearn\n",
    "\n",
    "Another type of regularised linear model is know as *Ridge regression*.\n",
    "\n",
    "* Repeat the model prediction process above on the credit data but use a ridge regression model.\n",
    "* Try replacing `GridSearchCV` with `RandomizedSearchCV`\n",
    "* How do these functions differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>-134.709207</td>\n",
       "      <td>-105.847146</td>\n",
       "      <td>-101.408319</td>\n",
       "      <td>-87.535423</td>\n",
       "      <td>-78.910802</td>\n",
       "      <td>-76.088537</td>\n",
       "      <td>-109.798419</td>\n",
       "      <td>-103.970825</td>\n",
       "      <td>-106.104415</td>\n",
       "      <td>-113.431271</td>\n",
       "      <td>-101.780436</td>\n",
       "      <td>16.463655</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>-134.708083</td>\n",
       "      <td>-105.847646</td>\n",
       "      <td>-101.405663</td>\n",
       "      <td>-87.537922</td>\n",
       "      <td>-78.910278</td>\n",
       "      <td>-76.089237</td>\n",
       "      <td>-109.797587</td>\n",
       "      <td>-103.951593</td>\n",
       "      <td>-106.104574</td>\n",
       "      <td>-113.432645</td>\n",
       "      <td>-101.778523</td>\n",
       "      <td>16.463002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>-134.696920</td>\n",
       "      <td>-105.852592</td>\n",
       "      <td>-101.379213</td>\n",
       "      <td>-87.562901</td>\n",
       "      <td>-78.905195</td>\n",
       "      <td>-76.096104</td>\n",
       "      <td>-109.789211</td>\n",
       "      <td>-103.762049</td>\n",
       "      <td>-106.106093</td>\n",
       "      <td>-113.446278</td>\n",
       "      <td>-101.759656</td>\n",
       "      <td>16.456623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>-134.591854</td>\n",
       "      <td>-105.896229</td>\n",
       "      <td>-101.125522</td>\n",
       "      <td>-87.810393</td>\n",
       "      <td>-78.868133</td>\n",
       "      <td>-76.152928</td>\n",
       "      <td>-109.700721</td>\n",
       "      <td>-102.109819</td>\n",
       "      <td>-106.115508</td>\n",
       "      <td>-113.572360</td>\n",
       "      <td>-101.594347</td>\n",
       "      <td>16.404872</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 3}</td>\n",
       "      <td>-134.391253</td>\n",
       "      <td>-105.965205</td>\n",
       "      <td>-100.621625</td>\n",
       "      <td>-88.340987</td>\n",
       "      <td>-78.849639</td>\n",
       "      <td>-76.222951</td>\n",
       "      <td>-109.483397</td>\n",
       "      <td>-99.544295</td>\n",
       "      <td>-106.108819</td>\n",
       "      <td>-113.805661</td>\n",
       "      <td>-101.333383</td>\n",
       "      <td>16.332863</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>-133.890522</td>\n",
       "      <td>-106.090432</td>\n",
       "      <td>-99.320843</td>\n",
       "      <td>-89.982387</td>\n",
       "      <td>-79.071589</td>\n",
       "      <td>-76.191060</td>\n",
       "      <td>-108.669389</td>\n",
       "      <td>-95.536294</td>\n",
       "      <td>-105.969953</td>\n",
       "      <td>-114.432072</td>\n",
       "      <td>-100.915454</td>\n",
       "      <td>16.192486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>-134.083288</td>\n",
       "      <td>-108.689604</td>\n",
       "      <td>-99.945650</td>\n",
       "      <td>-100.567871</td>\n",
       "      <td>-82.857511</td>\n",
       "      <td>-72.598275</td>\n",
       "      <td>-102.841444</td>\n",
       "      <td>-94.279222</td>\n",
       "      <td>-106.194183</td>\n",
       "      <td>-121.853714</td>\n",
       "      <td>-102.391076</td>\n",
       "      <td>16.678747</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'alpha': 1000}</td>\n",
       "      <td>-159.394337</td>\n",
       "      <td>-130.276230</td>\n",
       "      <td>-139.267945</td>\n",
       "      <td>-127.599179</td>\n",
       "      <td>-104.683784</td>\n",
       "      <td>-68.050042</td>\n",
       "      <td>-105.482490</td>\n",
       "      <td>-112.287832</td>\n",
       "      <td>-123.522302</td>\n",
       "      <td>-154.546831</td>\n",
       "      <td>-122.511097</td>\n",
       "      <td>25.363301</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.002194      0.000290         0.001376        0.000102       0.001   \n",
       "1       0.001663      0.000118         0.001141        0.000063        0.01   \n",
       "2       0.001553      0.000019         0.001107        0.000025         0.1   \n",
       "3       0.001373      0.000094         0.000995        0.000099           1   \n",
       "4       0.001424      0.000146         0.000959        0.000083           3   \n",
       "5       0.001303      0.000015         0.000908        0.000016          10   \n",
       "6       0.001295      0.000013         0.000924        0.000039         100   \n",
       "7       0.001298      0.000018         0.000906        0.000006        1000   \n",
       "\n",
       "             params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.001}        -134.709207        -105.847146        -101.408319   \n",
       "1   {'alpha': 0.01}        -134.708083        -105.847646        -101.405663   \n",
       "2    {'alpha': 0.1}        -134.696920        -105.852592        -101.379213   \n",
       "3      {'alpha': 1}        -134.591854        -105.896229        -101.125522   \n",
       "4      {'alpha': 3}        -134.391253        -105.965205        -100.621625   \n",
       "5     {'alpha': 10}        -133.890522        -106.090432         -99.320843   \n",
       "6    {'alpha': 100}        -134.083288        -108.689604         -99.945650   \n",
       "7   {'alpha': 1000}        -159.394337        -130.276230        -139.267945   \n",
       "\n",
       "   split3_test_score  split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0         -87.535423         -78.910802         -76.088537        -109.798419   \n",
       "1         -87.537922         -78.910278         -76.089237        -109.797587   \n",
       "2         -87.562901         -78.905195         -76.096104        -109.789211   \n",
       "3         -87.810393         -78.868133         -76.152928        -109.700721   \n",
       "4         -88.340987         -78.849639         -76.222951        -109.483397   \n",
       "5         -89.982387         -79.071589         -76.191060        -108.669389   \n",
       "6        -100.567871         -82.857511         -72.598275        -102.841444   \n",
       "7        -127.599179        -104.683784         -68.050042        -105.482490   \n",
       "\n",
       "   split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0        -103.970825        -106.104415        -113.431271      -101.780436   \n",
       "1        -103.951593        -106.104574        -113.432645      -101.778523   \n",
       "2        -103.762049        -106.106093        -113.446278      -101.759656   \n",
       "3        -102.109819        -106.115508        -113.572360      -101.594347   \n",
       "4         -99.544295        -106.108819        -113.805661      -101.333383   \n",
       "5         -95.536294        -105.969953        -114.432072      -100.915454   \n",
       "6         -94.279222        -106.194183        -121.853714      -102.391076   \n",
       "7        -112.287832        -123.522302        -154.546831      -122.511097   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0       16.463655                6  \n",
       "1       16.463002                5  \n",
       "2       16.456623                4  \n",
       "3       16.404872                3  \n",
       "4       16.332863                2  \n",
       "5       16.192486                1  \n",
       "6       16.678747                7  \n",
       "7       25.363301                8  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### your solution here\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "ridge = Ridge(max_iter=10000)\n",
    "\n",
    "param_grid = [\n",
    " {'alpha': [0.001, 0.01, 0.1, 1, 3, 10, 100, 1000]},\n",
    " ]\n",
    "grid_search_ridge = GridSearchCV(ridge, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "\n",
    "grid_results = pd.DataFrame(grid_search_ridge.cv_results_)\n",
    "\n",
    "grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>124.18432</td>\n",
       "      <td>{'alpha': 124.18431978438628}</td>\n",
       "      <td>-134.812626</td>\n",
       "      <td>-109.527649</td>\n",
       "      <td>-101.402646</td>\n",
       "      <td>-102.271025</td>\n",
       "      <td>-83.678092</td>\n",
       "      <td>-71.742080</td>\n",
       "      <td>-102.097047</td>\n",
       "      <td>-95.010700</td>\n",
       "      <td>-106.684787</td>\n",
       "      <td>-123.655286</td>\n",
       "      <td>-103.088194</td>\n",
       "      <td>17.067264</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.286565</td>\n",
       "      <td>{'alpha': 0.2865647929318674}</td>\n",
       "      <td>-134.674187</td>\n",
       "      <td>-105.862481</td>\n",
       "      <td>-101.325039</td>\n",
       "      <td>-87.614565</td>\n",
       "      <td>-78.895529</td>\n",
       "      <td>-76.109595</td>\n",
       "      <td>-109.771547</td>\n",
       "      <td>-103.384611</td>\n",
       "      <td>-106.108881</td>\n",
       "      <td>-113.473889</td>\n",
       "      <td>-101.722032</td>\n",
       "      <td>16.444214</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>126.591398</td>\n",
       "      <td>{'alpha': 126.59139752316108}</td>\n",
       "      <td>-134.891113</td>\n",
       "      <td>-109.611208</td>\n",
       "      <td>-101.553724</td>\n",
       "      <td>-102.429497</td>\n",
       "      <td>-83.758335</td>\n",
       "      <td>-71.662533</td>\n",
       "      <td>-102.033560</td>\n",
       "      <td>-95.084569</td>\n",
       "      <td>-106.737521</td>\n",
       "      <td>-123.828959</td>\n",
       "      <td>-103.159102</td>\n",
       "      <td>17.107298</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.950154</td>\n",
       "      <td>{'alpha': 0.9501538387890021}</td>\n",
       "      <td>-134.597389</td>\n",
       "      <td>-105.894062</td>\n",
       "      <td>-101.139088</td>\n",
       "      <td>-87.796811</td>\n",
       "      <td>-78.869603</td>\n",
       "      <td>-76.150286</td>\n",
       "      <td>-109.705820</td>\n",
       "      <td>-102.191139</td>\n",
       "      <td>-106.115234</td>\n",
       "      <td>-113.565809</td>\n",
       "      <td>-101.602524</td>\n",
       "      <td>16.407278</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>5.392922</td>\n",
       "      <td>{'alpha': 5.392921558298756}</td>\n",
       "      <td>-134.192204</td>\n",
       "      <td>-106.018812</td>\n",
       "      <td>-100.106150</td>\n",
       "      <td>-88.937687</td>\n",
       "      <td>-78.894243</td>\n",
       "      <td>-76.244853</td>\n",
       "      <td>-109.206323</td>\n",
       "      <td>-97.616017</td>\n",
       "      <td>-106.072223</td>\n",
       "      <td>-114.038304</td>\n",
       "      <td>-101.132682</td>\n",
       "      <td>16.275856</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>967.343154</td>\n",
       "      <td>{'alpha': 967.343154172192}</td>\n",
       "      <td>-158.855727</td>\n",
       "      <td>-129.806139</td>\n",
       "      <td>-138.485948</td>\n",
       "      <td>-127.124476</td>\n",
       "      <td>-104.174823</td>\n",
       "      <td>-67.945014</td>\n",
       "      <td>-105.229858</td>\n",
       "      <td>-111.919074</td>\n",
       "      <td>-123.137012</td>\n",
       "      <td>-153.983205</td>\n",
       "      <td>-122.066128</td>\n",
       "      <td>25.227055</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>31.244166</td>\n",
       "      <td>{'alpha': 31.244166260525304}</td>\n",
       "      <td>-133.225657</td>\n",
       "      <td>-106.499925</td>\n",
       "      <td>-97.765382</td>\n",
       "      <td>-93.663974</td>\n",
       "      <td>-80.134448</td>\n",
       "      <td>-75.460024</td>\n",
       "      <td>-106.584964</td>\n",
       "      <td>-93.123647</td>\n",
       "      <td>-105.614023</td>\n",
       "      <td>-116.196291</td>\n",
       "      <td>-100.826833</td>\n",
       "      <td>16.018206</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>114.014462</td>\n",
       "      <td>{'alpha': 114.01446224209333}</td>\n",
       "      <td>-134.491718</td>\n",
       "      <td>-109.174694</td>\n",
       "      <td>-100.774634</td>\n",
       "      <td>-101.580904</td>\n",
       "      <td>-83.336560</td>\n",
       "      <td>-72.089500</td>\n",
       "      <td>-102.385419</td>\n",
       "      <td>-94.700071</td>\n",
       "      <td>-106.469054</td>\n",
       "      <td>-122.910403</td>\n",
       "      <td>-102.791296</td>\n",
       "      <td>16.900357</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.52776</td>\n",
       "      <td>{'alpha': 0.5277595174724746}</td>\n",
       "      <td>-134.645571</td>\n",
       "      <td>-105.874581</td>\n",
       "      <td>-101.256268</td>\n",
       "      <td>-87.681097</td>\n",
       "      <td>-78.884660</td>\n",
       "      <td>-76.125636</td>\n",
       "      <td>-109.748149</td>\n",
       "      <td>-102.925449</td>\n",
       "      <td>-106.111805</td>\n",
       "      <td>-113.508374</td>\n",
       "      <td>-101.676159</td>\n",
       "      <td>16.429615</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.920493</td>\n",
       "      <td>{'alpha': 0.9204929606732325}</td>\n",
       "      <td>-134.600697</td>\n",
       "      <td>-105.892761</td>\n",
       "      <td>-101.147186</td>\n",
       "      <td>-87.788721</td>\n",
       "      <td>-78.870508</td>\n",
       "      <td>-76.148688</td>\n",
       "      <td>-109.708843</td>\n",
       "      <td>-102.240037</td>\n",
       "      <td>-106.115059</td>\n",
       "      <td>-113.561889</td>\n",
       "      <td>-101.607439</td>\n",
       "      <td>16.408730</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.001868      0.000181         0.001267        0.000124   124.18432   \n",
       "1        0.001695      0.000074         0.001158        0.000044    0.286565   \n",
       "2        0.001617      0.000084         0.001114        0.000019  126.591398   \n",
       "3        0.001493      0.000136         0.001110        0.000298    0.950154   \n",
       "4        0.001459      0.000258         0.000955        0.000075    5.392922   \n",
       "..            ...           ...              ...             ...         ...   \n",
       "95       0.001362      0.000133         0.000958        0.000140  967.343154   \n",
       "96       0.001293      0.000019         0.000895        0.000005   31.244166   \n",
       "97       0.001282      0.000006         0.000902        0.000017  114.014462   \n",
       "98       0.001282      0.000010         0.000903        0.000015     0.52776   \n",
       "99       0.001302      0.000050         0.000925        0.000084    0.920493   \n",
       "\n",
       "                           params  split0_test_score  split1_test_score  \\\n",
       "0   {'alpha': 124.18431978438628}        -134.812626        -109.527649   \n",
       "1   {'alpha': 0.2865647929318674}        -134.674187        -105.862481   \n",
       "2   {'alpha': 126.59139752316108}        -134.891113        -109.611208   \n",
       "3   {'alpha': 0.9501538387890021}        -134.597389        -105.894062   \n",
       "4    {'alpha': 5.392921558298756}        -134.192204        -106.018812   \n",
       "..                            ...                ...                ...   \n",
       "95    {'alpha': 967.343154172192}        -158.855727        -129.806139   \n",
       "96  {'alpha': 31.244166260525304}        -133.225657        -106.499925   \n",
       "97  {'alpha': 114.01446224209333}        -134.491718        -109.174694   \n",
       "98  {'alpha': 0.5277595174724746}        -134.645571        -105.874581   \n",
       "99  {'alpha': 0.9204929606732325}        -134.600697        -105.892761   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0         -101.402646        -102.271025         -83.678092   \n",
       "1         -101.325039         -87.614565         -78.895529   \n",
       "2         -101.553724        -102.429497         -83.758335   \n",
       "3         -101.139088         -87.796811         -78.869603   \n",
       "4         -100.106150         -88.937687         -78.894243   \n",
       "..                ...                ...                ...   \n",
       "95        -138.485948        -127.124476        -104.174823   \n",
       "96         -97.765382         -93.663974         -80.134448   \n",
       "97        -100.774634        -101.580904         -83.336560   \n",
       "98        -101.256268         -87.681097         -78.884660   \n",
       "99        -101.147186         -87.788721         -78.870508   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0          -71.742080        -102.097047         -95.010700   \n",
       "1          -76.109595        -109.771547        -103.384611   \n",
       "2          -71.662533        -102.033560         -95.084569   \n",
       "3          -76.150286        -109.705820        -102.191139   \n",
       "4          -76.244853        -109.206323         -97.616017   \n",
       "..                ...                ...                ...   \n",
       "95         -67.945014        -105.229858        -111.919074   \n",
       "96         -75.460024        -106.584964         -93.123647   \n",
       "97         -72.089500        -102.385419         -94.700071   \n",
       "98         -76.125636        -109.748149        -102.925449   \n",
       "99         -76.148688        -109.708843        -102.240037   \n",
       "\n",
       "    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0         -106.684787        -123.655286      -103.088194       17.067264   \n",
       "1         -106.108881        -113.473889      -101.722032       16.444214   \n",
       "2         -106.737521        -123.828959      -103.159102       17.107298   \n",
       "3         -106.115234        -113.565809      -101.602524       16.407278   \n",
       "4         -106.072223        -114.038304      -101.132682       16.275856   \n",
       "..                ...                ...              ...             ...   \n",
       "95        -123.137012        -153.983205      -122.066128       25.227055   \n",
       "96        -105.614023        -116.196291      -100.826833       16.018206   \n",
       "97        -106.469054        -122.910403      -102.791296       16.900357   \n",
       "98        -106.111805        -113.508374      -101.676159       16.429615   \n",
       "99        -106.115059        -113.561889      -101.607439       16.408730   \n",
       "\n",
       "    rank_test_score  \n",
       "0                80  \n",
       "1                64  \n",
       "2                81  \n",
       "3                50  \n",
       "4                26  \n",
       "..              ...  \n",
       "95              100  \n",
       "96                9  \n",
       "97               79  \n",
       "98               56  \n",
       "99               51  \n",
       "\n",
       "[100 rows x 19 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.fixes import loguniform\n",
    "ridge = Ridge(max_iter=10000)\n",
    "\n",
    "param_grid = [\n",
    " {'alpha': loguniform(0.1,1000)},\n",
    " ]\n",
    "grid_search_ridge = RandomizedSearchCV(ridge,param_grid,cv=10,n_iter=100, scoring='neg_mean_squared_error')\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "\n",
    "grid_results = pd.DataFrame(grid_search_ridge.cv_results_)\n",
    "\n",
    "grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_fit_time                            0.001296\n",
       "std_fit_time                             0.000022\n",
       "mean_score_time                          0.000912\n",
       "std_score_time                           0.000021\n",
       "param_alpha                             20.125308\n",
       "params               {'alpha': 20.12530845519356}\n",
       "split0_test_score                     -133.461995\n",
       "split1_test_score                     -106.253666\n",
       "split2_test_score                      -98.262553\n",
       "split3_test_score                      -91.920546\n",
       "split4_test_score                      -79.577756\n",
       "split5_test_score                      -75.892632\n",
       "split6_test_score                     -107.588994\n",
       "split7_test_score                      -93.721042\n",
       "split8_test_score                     -105.755754\n",
       "split9_test_score                     -115.261122\n",
       "mean_test_score                       -100.769606\n",
       "std_test_score                          16.070061\n",
       "rank_test_score                                 1\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.loc[grid_results.rank_test_score.idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Moneyball\n",
    "\n",
    "Moneyball, as well as being a fantastic story, is also a true story of statistical methods being applied in a real world context to make predictions for decision making. [The film Moneyball](https://www.youtube.com/watch?v=-4QPVo0UIzc) is well worth a watch if you have time. As well as in baseball most major competitive sports teams are now using data science to improve their performance, e.g. [football](http://outsideoftheboot.com/2013/06/26/rise-of-data-analysis-in-football/),...\n",
    "\n",
    "In this exercise you have been hired by Oakland Athletics general manager Billy Beane. Your first mission is to predict the salary each player will make based on other information that is available. This will allow Billy to understand what price he should pay for players in the next transfer season.\n",
    "\n",
    "You must:\n",
    "* Import and prepare the data\n",
    "* Create a train and test set\n",
    "* Implement a regularised model of your choice\n",
    "* Choose optimal parameters for your regularised model\n",
    "* Estimate test-error using k-fold cross validation\n",
    "* Calculate the true test-error\n",
    "\n",
    "<details><summary>HINT 1</summary><br>\n",
    "Some values are missing. You can drop these rows.\n",
    "</details>\n",
    "\n",
    "<details><summary>HINT 2</summary><br>\n",
    "Some columns do not contain numerical values. You can drop these columns.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### note data is in the Hitters.csv file\n",
    "\n",
    "#### your solution here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6:**\n",
    "* Ridge regression works best when the input variables are standardised. (See section 6.2 **ISLR** for more details.). Try standardising your data before running your model. Do you find different results?\n",
    "* does this model outperform a simple linear regression model?\n",
    "* Which variables are most important in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stats_3]",
   "language": "python",
   "name": "conda-env-stats_3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
